{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8293520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict,Literal,Annotated\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e270f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea40430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63a2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSchema(TypedDict):\n",
    "    topic:str\n",
    "    notes:str\n",
    "    questions:str\n",
    "    status:Literal[\"approved\",\"rejected\"]\n",
    "    score:float\n",
    "    feedback:str\n",
    "    iterator:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72e4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesSchema(BaseModel):\n",
    "    notes:Annotated[str,Field(description=\"200 words summary of the given topic\")]\n",
    "    questions:Annotated[str,Field(description=\"3 MCQ questions that test the most important concepts for the given topic\")]\n",
    "\n",
    "class EvaluationSchema(BaseModel):\n",
    "    status:Literal[\"approved\",\"rejected\"]\n",
    "    feedback:Annotated[str,Field(description=\"Provide the feeback about the notes\")]\n",
    "    score:Annotated[float,Field(description=\"Rate the score out of 5\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb9cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model1=model.with_structured_output(NotesSchema)\n",
    "structured_model2=model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca71769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(state:StateSchema)->StateSchema:\n",
    "\n",
    "    prompt=f\"You are my example helper. I will give you a topic and you have to generate notes for the things that I must remember so that I get good grades in my exame. It should not be longer than 200 words and avoid mathematical derivation, just summary of the topic that I give you.Also give me 3 MCQ questions that test the most important concepts for the given topic:{state['topic']}\"\n",
    "\n",
    "    result=structured_model1.invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        \"notes\": result.notes,\n",
    "        \"questions\":result.questions,\n",
    "        \"iterator\":0\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169b92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_notes(state:StateSchema):\n",
    "\n",
    "    prompt=f\"This is a very tricky situtation. Say I have not studied for my exams and this is the only shot I have got. I'll provide you with a summary of the notes that I have. Can you accept or reject the notes based on if it provides an detailed overview of the given topic which will help me pass an exam. Also provide me a score on the notes and feedback on it: {state['notes']}\"\n",
    "\n",
    "    result=structured_model2.invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        \"status\": result.status,\n",
    "        \"feedback\":result.feedback,\n",
    "        \"score\":result.score\n",
    "    }\n",
    "\n",
    "def optimize_notes(state:StateSchema):\n",
    "    prompt=f\"Can you optimize the given notes:{state['notes']} based on the given feedback:{state['feedback']}. You can summarize it within 500 words and also provide 3 MCQ questions that best reflect the given topic\"\n",
    "    result=structured_model1.invoke(prompt)\n",
    "    iteration=state[\"iterator\"]+1\n",
    "\n",
    "    return {\n",
    "        \"notes\": result.notes,\n",
    "        \"questions\":result.questions,\n",
    "        \"iterator\":iteration\n",
    "    }\n",
    "\n",
    "def conditional_edge(state:StateSchema):\n",
    "    if state[\"status\"]==\"approved\" or state[\"iterator\"]==5:\n",
    "        return \"approved\"\n",
    "    else:\n",
    "        return \"rejected\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84240be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(StateSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b145fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2559ddc9f90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node('generate',generate_notes)\n",
    "graph.add_node('evaluate',evaluate_notes)\n",
    "graph.add_node('optimize',optimize_notes)\n",
    "\n",
    "graph.add_edge(START,'generate')\n",
    "graph.add_edge('generate','evaluate')\n",
    "\n",
    "graph.add_conditional_edges('evaluate',conditional_edge,{'approved':END,'rejected':'optimize'})\n",
    "graph.add_edge('optimize',END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8b1178",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 400.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khadk\\OneDrive\\anaconda3\\envs\\llm_new_env\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khadk\\OneDrive\\anaconda3\\envs\\llm_new_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:775\u001b[39m, in \u001b[36mPregel._repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    772\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001b[39;00m\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    774\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    776\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khadk\\OneDrive\\anaconda3\\envs\\llm_new_env\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config, base_url, proxies)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    684\u001b[39m     draw_mermaid_png,\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khadk\\OneDrive\\anaconda3\\envs\\llm_new_env\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:313\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, base_url, proxies)\u001b[39m\n\u001b[32m    307\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    308\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    309\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    310\u001b[39m         )\n\u001b[32m    311\u001b[39m     )\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    323\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khadk\\OneDrive\\anaconda3\\envs\\llm_new_env\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:476\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay, proxies, base_url)\u001b[39m\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    472\u001b[39m     msg = (\n\u001b[32m    473\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    474\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    480\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 400.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x2559ddd4410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow=graph.compile()\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359d02ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Convolution Neural Network',\n",
       " 'notes': 'A Convolutional Neural Network (CNN) is a type of deep learning model that uses convolutional and pooling layers to analyze data with grid-like topology. It is commonly used in image and video processing tasks. The key concept in CNN is the convolutional layer, which applies a filter to a small region of the input data, producing a feature map. The pooling layer reduces the spatial dimensions of the feature map, helping to reduce the number of parameters and prevent overfitting. CNNs are particularly useful for tasks like image classification, object detection, and image segmentation. The key components of a CNN include convolutional layers, pooling layers, fully connected layers, and activation functions like ReLU and Sigmoid.',\n",
       " 'questions': '1. What is the primary function of a convolutional layer in a CNN? A) To apply a filter to a small region of the input data B) To reduce the spatial dimensions of the feature map C) To classify the input data D) To detect objects in an image Answer: A) To apply a filter to a small region of the input data. \\n2. What is the purpose of a pooling layer in a CNN? A) To increase the spatial dimensions of the feature map B) To reduce the spatial dimensions of the feature map C) To apply a filter to a small region of the input data D) To classify the input data Answer: B) To reduce the spatial dimensions of the feature map. \\n3. What is the primary function of a fully connected layer in a CNN? A) To apply a filter to a small region of the input data B) To reduce the spatial dimensions of the feature map C) To classify the input data D) To detect objects in an image Answer: C) To classify the input data.',\n",
       " 'status': 'approved',\n",
       " 'score': 3.0,\n",
       " 'feedback': 'The provided notes offer a concise overview of the key concepts in Convolutional Neural Networks, including the functionality of convolutional and pooling layers, the role of key components, and the applications of CNNs in image and video processing. However, it lacks detailed information on the internal workings of the model and specific mathematical formulations, which might make it challenging for someone who has not studied the topic before to fully comprehend. Nevertheless, with some additional context and examples, this summary could be a useful starting point for a beginner or a quick review for a more advanced learner.',\n",
       " 'iterator': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state={\n",
    "    'topic':'Convolution Neural Network'\n",
    "}\n",
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
